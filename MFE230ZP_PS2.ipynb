{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83708667-4fdc-1563-7b3a-06b6575d2865",
    "id": "EsPRZn0KgzCp"
   },
   "source": [
    "\n",
    "\n",
    "# Predicting ad clicking behavior with LASSO, elastic net, decision tree, random forest, and XGBoost.\n",
    "\n",
    "In this exercise, we will predict users' ad clicking behavior using a LASSO model, a elastic net model, a decision tree, a random forest, and XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIDLr5bQgzCy"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## Loading the python packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "5d8fee34-f454-2642-8b06-ed719f0317e1",
    "id": "Jy3KpFmogzCy"
   },
   "source": [
    "# Load libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# for higher resolution\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg','pdf')\n",
    "\n",
    "# nice format for matplotlib https://tonysyu.github.io/raw_content/matplotlib-style-gallery/gallery.html\n",
    "plt.style.use('bmh')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "#Libraries for Deep Learning Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import SGD\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2IRYkfEgzCz"
   },
   "source": [
    "<a id='1.2'></a>\n",
    "## Loading the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "787e35f7-bf9e-0969-8d13-a54fa87f3519",
    "id": "bbbPQAGigzC0"
   },
   "source": [
    "# load sample dataset (only load the first 300000 rows) (1pts)\n",
    "data = pd.read_csv('PS2_casestudy_data.csv')\n",
    "# data = data.drop(data.columns[0], axis=1).head(300000) #try a smaller size first\n",
    "data = data.drop(data.columns[0], axis=1).head(50000) #try a smaller size first\n",
    "data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.info()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QycYb2JnwFa9"
   },
   "source": [
    "#Explore the data (print the first and last 5 rows) (2pts)\n",
    "print('First five rows:')\n",
    "print(data.head(5))\n",
    "print('Last five rows:')\n",
    "print(data.tail(5))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rQ0bp7RYDZAZ"
   },
   "source": [
    "#remove nas from dataframe by simply dropping these rows (2pts)\n",
    "data.dropna()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "em4ivCnZDbZG"
   },
   "source": [
    "#create Y and X. Y is the \"click\" column, and X is the other 19 columns (Do not use ['id', 'hour', 'device_id', 'device_ip']) (1pts)\n",
    "Y = data['click']\n",
    "X = data.drop(columns=['click', 'id', 'hour', 'device_id', 'device_ip'])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Use sklearn one-hot encoder to transform string variables in X to categorical columns (make sure to save the data as a sparse matrxi) (3pts)\n",
    "\n",
    "string_cols = [i for i in X.columns if X[i].dtype is np.dtype('object')]\n",
    "print(string_cols)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=True, handle_unknown = 'ignore')  #sparse=True)#, drop='first')\n",
    "\n",
    "encoded_x = encoder.fit_transform(X[string_cols])\n",
    "\n",
    "# encoded_df = pd.DataFrame(encoded_x.toarray(), columns=encoder.get_feature_names_out(string_cols))\n",
    "\n",
    "unencoded_x = X[[col for col in X.columns if col not in list(string_cols)]].values\n",
    "\n",
    "X_encoded = np.hstack([unencoded_x, encoded_x.toarray()])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5eNTO35fDfcd"
   },
   "source": [
    "#do a train-test split. Use the first 90% of the data as training. (1pts)\n",
    "scaler = StandardScaler()\n",
    "X_updated = scaler.fit_transform(X_encoded)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_updated, Y.values, test_size=0.1, random_state = 42)\n",
    "\n",
    "# Save the encoded data as a sparse matrix\n",
    "# X_train = sparse.csr_matrix(X_train)\n",
    "# X_test = sparse.csr_matrix(X_test)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4cGwpXtDx5X"
   },
   "source": [
    "\n",
    "## LASSO and ElasticNet\n",
    "First use a sklearn LASSO model with alpha=0.005 (regularization penalty) to predict clicking behavior. Report the prediction accuracy. Then use sklearn elastic net with alpha = 0.005 and l1_ratio=0.5 (l1_ratio is a number from 0 to 1 which represents the portion of L1 penalization in the total penalization term)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WiaW0m8RDzb7"
   },
   "source": [
    "#initialize and training the model (1pts)\n",
    "lasso_model = Lasso(alpha=0.005)\n",
    "lasso_model.fit(X_train, Y_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IfLro9zeD3mh"
   },
   "source": [
    "#testing the model (2pts)\n",
    "Y_pred_lasso = lasso_model.predict(X_test)\n",
    "lasso_accuracy = accuracy_score(Y_pred_lasso, Y_test)\n",
    "print(f\"LASSO accuracy: {lasso_accuracy}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0r5RaLqy2LTo"
   },
   "source": [
    "#initialize and training the elastic net (2pts)\n",
    "elasticnet_model = ElasticNet(alpha=0.005, l1_ratio=0.5)\n",
    "elasticnet_model.fit(X_train, Y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XNN0KEZ12Lbc"
   },
   "source": [
    "#testing the elastic net (2pts)\n",
    "elasticnet_accuracy = accuracy_score(elasticnet_model.predict(X_test), Y_test)\n",
    "# elasticnet_mse = mean_squared_error(Y_test, Y_pred_elasticnet)\n",
    "print(f\"ElasticNet accuracy: {elasticnet_accuracy}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think is causing these differences? \n",
    "\n",
    "First, LASSO uses L1 regularization to perform variable selection, but it may miss capturing complex relationships between features. ElasticNet combines both L1 and L2 regularization, which can better handle scenarios with highly correlated variables, providing a balance between variable selection and coefficient shrinkage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNiqHGRkDkHL"
   },
   "source": [
    "## Decision tree and random forest"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jghyvb8IDogl"
   },
   "source": [
    "#build a single decision tree model using gini impurity and roc_auc scoring (2pts)\n",
    "decision_tree = DecisionTreeClassifier(criterion='gini')\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "y_predict = decision_tree.predict(X_test)\n",
    "roc_auc_score(Y_test, y_predict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yhFeR8V398zU"
   },
   "source": [
    "#do a grid search on the max-depth variable [3,10,None]. (3pts)\n",
    "param_grid = {'max_depth': [3, 10, None]}\n",
    "grid_search_dt = GridSearchCV(decision_tree, param_grid, scoring='roc_auc', cv=5)\n",
    "grid_search_dt.fit(X_train, Y_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OAJSxCOADrTT"
   },
   "source": [
    "#print the auc of the optimal model applied on the test set (3pts)\n",
    "# best_dt_model = grid_search_dt.best_estimator_\n",
    "# Y_pred_dt = best_dt_model.predict_proba(X_test)[:, 1]\n",
    "# auc_dt = roc_auc_score(Y_test, Y_pred_dt)\n",
    "auc_dt = roc_auc_score(list(Y_test), list(grid_search_dt.predict(X_test)))\n",
    "print(f\"Decision Tree Best AUC: {auc_dt}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R5DEclYmDtCo"
   },
   "source": [
    "#build a random forest using gini impurity and roc_auc scoring (2pts)\n",
    "random_forest = RandomForestClassifier(criterion='gini')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E8XQ2OtS9_J2"
   },
   "source": [
    "#do grid search to tune n_estimators and max_depth -- 'max_depth': [3, 10, None],'n_estimators': [10,50,100,200]. (3pts)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [3, 10, None]\n",
    "}\n",
    "grid_search_rf = GridSearchCV(random_forest, param_grid_rf, scoring='roc_auc', n_jobs = 4)\n",
    "grid_search_rf.fit(X_train, Y_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eDRgjTFpDujj"
   },
   "source": [
    "#print the performance of the best model (3pts)\n",
    "# best_rf_model = grid_search_rf.best_estimator_\n",
    "# Y_pred_rf = best_rf_model.predict_proba(X_test)[:, 1]\n",
    "# auc_rf = roc_auc_score(Y_test, Y_pred_rf)\n",
    "\n",
    "auc_rf = roc_auc_score(list(Y_test), list(grid_search_rf.predict(X_test)))\n",
    "print(f\"Random Forest Best AUC: {auc_rf}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8HRfdAD9few"
   },
   "source": [
    "## XGBoost\n",
    "\n",
    "Use the XGBoost classifier to predict clicking behavior. Fine-tune n_estimators over $[10,50,100]$ and $\\eta$ (eta) over $[0.01,0.05,0.1]$. Use roc_auc as the scoring criterion for CV."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rxmW_oCE9mLy"
   },
   "source": [
    "#initialize the parameter grid and the model (2ptsï¼‰\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xj96TYU79mRb"
   },
   "source": [
    "#do grid search (3pts)\n",
    "grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, scoring='roc_auc', cv=5)\n",
    "grid_search_xgb.fit(X_train, Y_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hHLWG1pW9mYU"
   },
   "source": [
    "#print the performance of the best model (2pts)\n",
    "# best_xgb_model = grid_search_xgb.best_estimator_\n",
    "# Y_pred_xgb = best_xgb_model.predict_proba(X_test)[:, 1]\n",
    "# auc_xgb = roc_auc_score(Y_test, Y_pred_xgb)\n",
    "\n",
    "auc_xgb = roc_auc_score(list(Y_test), list(grid_search_xgb.predict(X_test)))\n",
    "print(f\"XGBoost Best ROC AUC: {auc_xgb}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "undVbvp39mfS"
   },
   "source": [
    "#Looking at the CV results of the decision tree, random forest, and XGBoost model, which ones are likely underfitted/overfitted. (3pts)\n",
    "# cv_results = grid_search_xgb.cv_results_\n",
    "# for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "#     print(f\"Mean Test ROC AUC: {mean_score} with params: {params}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "_change_revision": 206,
  "_is_fork": false,
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
