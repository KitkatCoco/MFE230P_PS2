{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-01T19:35:55.776892200Z",
     "start_time": "2024-08-01T19:35:55.755584800Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=10, min_gain=0.05, max_leaf=50):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_gain = min_gain\n",
    "        self.max_leaf = max_leaf\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        if depth >= self.max_depth or len(np.unique(y)) == 1:\n",
    "            return self._create_leaf(y)\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if best_split['gain'] < self.min_gain:\n",
    "            return self._create_leaf(y)\n",
    "\n",
    "        left_indices = X[:, best_split['feature']] <= best_split['threshold']\n",
    "        right_indices = X[:, best_split['feature']] > best_split['threshold']\n",
    "\n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return {\n",
    "            'feature': best_split['feature'],\n",
    "            'threshold': best_split['threshold'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_split = {'gain': -1}\n",
    "        n_samples, n_features = X.shape\n",
    "        for feature in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(X[:, feature], y, threshold)\n",
    "                if gain > best_split['gain']:\n",
    "                    best_split = {\n",
    "                        'feature': feature,\n",
    "                        'threshold': threshold,\n",
    "                        'gain': gain\n",
    "                    }\n",
    "        return best_split\n",
    "\n",
    "    def _information_gain(self, feature_values, y, threshold):\n",
    "        parent_variance = self._variance(y)\n",
    "        left_indices = feature_values <= threshold\n",
    "        right_indices = feature_values > threshold\n",
    "        if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "            return 0\n",
    "\n",
    "        n = len(y)\n",
    "        n_left = len(y[left_indices])\n",
    "        n_right = len(y[right_indices])\n",
    "\n",
    "        var_left = self._variance(y[left_indices])\n",
    "        var_right = self._variance(y[right_indices])\n",
    "\n",
    "        child_variance = (n_left / n) * var_left + (n_right / n) * var_right\n",
    "        ig = parent_variance - child_variance\n",
    "        return ig\n",
    "\n",
    "    def _variance(self, y):\n",
    "        return np.var(y)\n",
    "\n",
    "    def _create_leaf(self, y):\n",
    "        return np.mean(y)\n",
    "\n",
    "    def _predict_single(self, x, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        feature = tree['feature']\n",
    "        threshold = tree['threshold']\n",
    "        if x[feature] <= threshold:\n",
    "            return self._predict_single(x, tree['left'])\n",
    "        else:\n",
    "            return self._predict_single(x, tree['right'])\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=10, min_gain=0.1, max_leaf=200):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_gain = min_gain\n",
    "        self.max_leaf = max_leaf\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            indices = np.random.choice(len(X), size=len(X), replace=True)\n",
    "            X_subset, y_subset = X[indices], y[indices]\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_gain=self.min_gain, max_leaf=self.max_leaf)\n",
    "            tree.fit(X_subset, y_subset)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(tree_predictions, axis=0)\n",
    "\n",
    "class RandomForestWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_trees=10, max_depth=10, min_gain=0.1, max_leaf=200):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_gain = min_gain\n",
    "        self.max_leaf = max_leaf\n",
    "        self.model = RandomForest(n_trees=n_trees, max_depth=max_depth, min_gain=min_gain, max_leaf=max_leaf)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "def create_preprocessing_pipeline(continuous_features, categorical_features, n_bins=10):\n",
    "    kbd = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    # ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('kbd', kbd, continuous_features),\n",
    "            ('ohe', ohe, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    return preprocessor\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T19:35:58.907762600Z",
     "start_time": "2024-08-01T19:35:58.467986300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the pipeline\n",
    "with open('random_forest_pipeline.pkl', 'rb') as f:\n",
    "    loaded_pipeline = pickle.load(f)\n",
    "\n",
    "# Read test data\n",
    "test_file = 'train_data2.csv'  # Specify your test data file\n",
    "df_test = pd.read_csv(test_file, index_col=0)\n",
    "\n",
    "X_test = df_test.drop(columns=['outcome'])\n",
    "y_true = df_test['outcome'].values\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = loaded_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error and plot actual vs predicted values\n",
    "mse = np.mean((y_true - y_pred) ** 2)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_true, y_pred)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()"
   ],
   "id": "45d69060b4a6597f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunpe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KBinsDiscretizer from version 1.3.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\yunpe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.3.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\yunpe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.3.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\yunpe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.3.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\yunpe\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.3.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m y_true \u001B[38;5;241m=\u001B[39m df_test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutcome\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Predict on the test set\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mloaded_pipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Calculate the mean squared error and plot actual vs predicted values\u001B[39;00m\n\u001B[0;32m     16\u001B[0m mse \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean((y_true \u001B[38;5;241m-\u001B[39m y_pred) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py:603\u001B[0m, in \u001B[0;36mPipeline.predict\u001B[1;34m(self, X, **params)\u001B[0m\n\u001B[0;32m    601\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _routing_enabled():\n\u001B[0;32m    602\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, name, transform \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter(with_final\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 603\u001B[0m         Xt \u001B[38;5;241m=\u001B[39m \u001B[43mtransform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    604\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mpredict(Xt, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m    606\u001B[0m \u001B[38;5;66;03m# metadata routing enabled\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_set_output.py:313\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 313\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    315\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    316\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    317\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    318\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    319\u001B[0m         )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\compose\\_column_transformer.py:1077\u001B[0m, in \u001B[0;36mColumnTransformer.transform\u001B[1;34m(self, X, **params)\u001B[0m\n\u001B[0;32m   1074\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1075\u001B[0m     routed_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_empty_routing()\n\u001B[1;32m-> 1077\u001B[0m Xs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_func_on_transformers\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_transform_one\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumn_as_labels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_dataframe_and_transform_dataframe\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1083\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1084\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_output(Xs)\n\u001B[0;32m   1086\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m Xs:\n\u001B[0;32m   1087\u001B[0m     \u001B[38;5;66;03m# All transformers are None\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\compose\\_column_transformer.py:886\u001B[0m, in \u001B[0;36mColumnTransformer._call_func_on_transformers\u001B[1;34m(self, X, y, func, column_as_labels, routed_params)\u001B[0m\n\u001B[0;32m    873\u001B[0m             extra_args \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    874\u001B[0m         jobs\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m    875\u001B[0m             delayed(func)(\n\u001B[0;32m    876\u001B[0m                 transformer\u001B[38;5;241m=\u001B[39mclone(trans) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fitted \u001B[38;5;28;01melse\u001B[39;00m trans,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    883\u001B[0m             )\n\u001B[0;32m    884\u001B[0m         )\n\u001B[1;32m--> 886\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    888\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    889\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\parallel.py:129\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    127\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py:1299\u001B[0m, in \u001B[0;36m_transform_one\u001B[1;34m(transformer, X, y, weight, columns, params)\u001B[0m\n\u001B[0;32m   1296\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1297\u001B[0m     X \u001B[38;5;241m=\u001B[39m _safe_indexing(X, columns, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m-> 1299\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mtransform)\n\u001B[0;32m   1300\u001B[0m \u001B[38;5;66;03m# if we have a weight for this transformer, multiply output\u001B[39;00m\n\u001B[0;32m   1301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'transform'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "c17d9730155347f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mfe230",
   "language": "python",
   "display_name": "mfe230"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
