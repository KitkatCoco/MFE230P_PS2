{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-08-01T21:27:40.730438500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Trees: 100%|██████████| 10/10 [07:41<00:00, 46.11s/it]\n",
      "Making Predictions: 100%|██████████| 10/10 [00:00<00:00, 66.20it/s]\n",
      "Training Trees: 100%|██████████| 10/10 [07:36<00:00, 45.68s/it]\n",
      "Making Predictions: 100%|██████████| 10/10 [00:00<00:00, 65.17it/s]\n",
      "Training Trees: 100%|██████████| 10/10 [07:57<00:00, 47.78s/it]\n",
      "Making Predictions: 100%|██████████| 10/10 [00:00<00:00, 65.76it/s]\n",
      "Training Trees: 100%|██████████| 10/10 [07:47<00:00, 46.77s/it]\n",
      "Making Predictions: 100%|██████████| 10/10 [00:00<00:00, 65.50it/s]\n",
      "Training Trees: 100%|██████████| 10/10 [07:42<00:00, 46.27s/it]\n",
      "Making Predictions: 100%|██████████| 10/10 [00:00<00:00, 68.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: max_depth=10, n_trees=10 - MSE: 2650.0364013240805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Trees: 100%|██████████| 30/30 [21:52<00:00, 43.74s/it]  \n",
      "Making Predictions: 100%|██████████| 30/30 [00:00<00:00, 66.97it/s]\n",
      "Training Trees: 100%|██████████| 30/30 [21:21<00:00, 42.72s/it]  \n",
      "Making Predictions: 100%|██████████| 30/30 [00:00<00:00, 67.44it/s]\n",
      "Training Trees: 100%|██████████| 30/30 [20:49<00:00, 41.65s/it]  \n",
      "Making Predictions: 100%|██████████| 30/30 [00:00<00:00, 69.01it/s]\n",
      "Training Trees: 100%|██████████| 30/30 [21:00<00:00, 42.02s/it]  \n",
      "Making Predictions: 100%|██████████| 30/30 [00:00<00:00, 69.00it/s]\n",
      "Training Trees: 100%|██████████| 30/30 [21:26<00:00, 42.89s/it]  \n",
      "Making Predictions: 100%|██████████| 30/30 [00:00<00:00, 66.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: max_depth=10, n_trees=30 - MSE: 2612.8822379329476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Trees: 100%|██████████| 50/50 [34:46<00:00, 41.72s/it]  \n",
      "Making Predictions: 100%|██████████| 50/50 [00:00<00:00, 68.15it/s]\n",
      "Training Trees: 100%|██████████| 50/50 [34:58<00:00, 41.96s/it]  \n",
      "Making Predictions: 100%|██████████| 50/50 [00:00<00:00, 65.79it/s]\n",
      "Training Trees:   8%|▊         | 4/50 [05:20<1:01:26, 80.13s/it] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=10, min_gain=0.05, max_leaf=50):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_gain = min_gain\n",
    "        self.max_leaf = max_leaf\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        if depth >= self.max_depth or len(np.unique(y)) == 1:\n",
    "            return self._create_leaf(y)\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        if best_split['gain'] < self.min_gain:\n",
    "            return self._create_leaf(y)\n",
    "\n",
    "        left_indices = X[:, best_split['feature']] <= best_split['threshold']\n",
    "        right_indices = X[:, best_split['feature']] > best_split['threshold']\n",
    "\n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return {\n",
    "            'feature': best_split['feature'],\n",
    "            'threshold': best_split['threshold'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_split = {'gain': -1}\n",
    "        n_samples, n_features = X.shape\n",
    "        for feature in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(X[:, feature], y, threshold)\n",
    "                if gain > best_split['gain']:\n",
    "                    best_split = {\n",
    "                        'feature': feature,\n",
    "                        'threshold': threshold,\n",
    "                        'gain': gain\n",
    "                    }\n",
    "        return best_split\n",
    "\n",
    "    def _information_gain(self, feature_values, y, threshold):\n",
    "        parent_variance = self._variance(y)\n",
    "        left_indices = feature_values <= threshold\n",
    "        right_indices = feature_values > threshold\n",
    "        if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "            return 0\n",
    "\n",
    "        n = len(y)\n",
    "        n_left = len(y[left_indices])\n",
    "        n_right = len(y[right_indices])\n",
    "\n",
    "        var_left = self._variance(y[left_indices])\n",
    "        var_right = self._variance(y[right_indices])\n",
    "\n",
    "        child_variance = (n_left / n) * var_left + (n_right / n) * var_right\n",
    "        ig = parent_variance - child_variance\n",
    "        return ig\n",
    "\n",
    "    def _variance(self, y):\n",
    "        return np.var(y)\n",
    "\n",
    "    def _create_leaf(self, y):\n",
    "        return np.mean(y)\n",
    "\n",
    "    def _predict_single(self, x, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        feature = tree['feature']\n",
    "        threshold = tree['threshold']\n",
    "        if x[feature] <= threshold:\n",
    "            return self._predict_single(x, tree['left'])\n",
    "        else:\n",
    "            return self._predict_single(x, tree['right'])\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=10, min_gain=0.1, max_leaf=200, n_jobs=4):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_gain = min_gain\n",
    "        self.max_leaf = max_leaf\n",
    "        self.n_jobs = n_jobs\n",
    "        self.trees = []\n",
    "\n",
    "    def _fit_tree(self, X, y):\n",
    "        indices = np.random.choice(len(X), size=len(X), replace=True)\n",
    "        X_subset, y_subset = X[indices], y[indices]\n",
    "        tree = DecisionTree(max_depth=self.max_depth, min_gain=self.min_gain, max_leaf=self.max_leaf)\n",
    "        tree.fit(X_subset, y_subset)\n",
    "        return tree\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = [executor.submit(self._fit_tree, X, y) for _ in range(self.n_trees)]\n",
    "            for future in tqdm(futures, desc=\"Training Trees\"):\n",
    "                self.trees.append(future.result())\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_predictions = np.array([tree.predict(X) for tree in tqdm(self.trees, desc=\"Making Predictions\")])\n",
    "        return np.mean(tree_predictions, axis=0)\n",
    "\n",
    "class RandomForestWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_trees=10, max_depth=10, min_gain=0.1, max_leaf=200, n_jobs=4):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_gain = min_gain\n",
    "        self.max_leaf = max_leaf\n",
    "        self.n_jobs = n_jobs\n",
    "        self.model = RandomForest(n_trees=n_trees, max_depth=max_depth, min_gain=min_gain, max_leaf=max_leaf, n_jobs=n_jobs)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "def create_preprocessing_pipeline(continuous_features, categorical_features, n_bins=10):\n",
    "    kbd = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('kbd', kbd, continuous_features),\n",
    "            ('ohe', ohe, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "def grid_search_with_cv(X, y):\n",
    "    param_grid = {\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'n_trees': [10, 30, 50]\n",
    "    }\n",
    "\n",
    "    best_params = None\n",
    "    best_mse = float('inf')\n",
    "    results = []\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    for max_depth in param_grid['max_depth']:\n",
    "        for n_trees in param_grid['n_trees']:\n",
    "            model = RandomForest(n_trees=n_trees, max_depth=max_depth, min_gain=0.1, max_leaf=200, n_jobs=4)\n",
    "            mse_scores = []\n",
    "\n",
    "            for train_index, val_index in kf.split(X):\n",
    "                X_train, X_val = X[train_index], X[val_index]\n",
    "                y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_val)\n",
    "                mse_scores.append(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "            avg_mse = np.mean(mse_scores)\n",
    "            results.append((max_depth, n_trees, avg_mse))\n",
    "            print(f\"Params: max_depth={max_depth}, n_trees={n_trees} - MSE: {avg_mse}\")\n",
    "\n",
    "            if avg_mse < best_mse:\n",
    "                best_mse = avg_mse\n",
    "                best_params = (max_depth, n_trees)\n",
    "\n",
    "    print(f\"Best Params: max_depth={best_params[0]}, n_trees={best_params[1]} - MSE: {best_mse}\")\n",
    "    return best_params, results\n",
    "\n",
    "def visualize_grid_search(results):\n",
    "    max_depths = [r[0] for r in results]\n",
    "    n_trees = [r[1] for r in results]\n",
    "    mses = [r[2] for r in results]\n",
    "\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=max_depths, y=n_trees, z=mses,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=mses,\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title='MSE'),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    )])\n",
    "\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='Max Depth',\n",
    "            yaxis_title='Number of Trees',\n",
    "            zaxis_title='MSE'\n",
    "        ),\n",
    "        title='Grid Search Results'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the data\n",
    "    df = pd.read_csv('train_data2.csv', index_col=0)\n",
    "    continuous_features = ['macro_state_1', 'macro_state_2']\n",
    "    categorical_features = ['category1', 'category2']\n",
    "\n",
    "    preprocessor = create_preprocessing_pipeline(continuous_features, categorical_features, n_bins=10)\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestWrapper(n_trees=30, max_depth=10, n_jobs=12))\n",
    "    ])\n",
    "\n",
    "    X = df.drop(columns=['outcome'])\n",
    "    y = df['outcome']\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    best_params, results = grid_search_with_cv(X.values, y.values)\n",
    "    visualize_grid_search(results)\n",
    "\n",
    "    # Fit the pipeline on the full dataset\n",
    "    pipeline.set_params(model__n_trees=best_params[1], model__max_depth=best_params[0])\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    # Save the pipeline to disk\n",
    "    with open('random_forest_pipeline.pkl', 'wb') as f:\n",
    "        pickle.dump(pipeline, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46a060050ba5970a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "mfe230",
   "language": "python",
   "display_name": "mfe230"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
